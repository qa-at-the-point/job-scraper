{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAP Job Poster\n",
    "\n",
    "This is the main code for posting open jobs for QA Professionals!\n",
    "\n",
    "At a high-level, this notebook goes through the process. Following the code will:\n",
    "\n",
    "* Collect jobs from different sources (ie Indeed, Google Jobs)\n",
    "* Filter relevant jobs using AI\n",
    "* Post those jobs to the `#jobs` channel in the QAP Slack Community!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the SQLite Database to save our results from collecting jobs\n",
    "\n",
    "* import everything we'll need for this notebook\n",
    "* delete the database (if exists) and create a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "from pylenium.driver import Pylenium, PyleniumConfig\n",
    "\n",
    "from jobs import ai, database, indeed, slack\n",
    "from jobs.models import Job\n",
    "\n",
    "database.delete()\n",
    "database.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use Pylenium to scrape jobs from different sources\n",
    "\n",
    "* Currently, uses `Indeed.com`\n",
    "* Eventually, will also use `Google Jobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "py = Pylenium(PyleniumConfig())\n",
    "scraped_jobs = indeed.scrape(py, indeed.REMOTE_QA_ENGINEER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save scraped jobs to our `indeed_jobs` table\n",
    "\n",
    "We don't want to lose these results in case an error happens or if we want to use it for something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.insert_indeed_jobs(scraped_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use AI to filter irrelevant jobs\n",
    "\n",
    "Unfortunately, Indeed doesn't do a great job of returning relevant results given their search and filters.\n",
    "\n",
    "Fortunately, we can use AI to not only give us the relevant jobs, but to also rank them:\n",
    "\n",
    "* Find jobs that would be relevant to Software QA Professionals\n",
    "* Order them from junior-level to senior-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the least amount of tokens to get the relevant jobs from all the scraped jobs\n",
    "# The AI responds with a string\n",
    "ai_response: str = ai.get_relevant_jobs(scraped_jobs)\n",
    "\n",
    "# Convert the string output from the AI to a list of dictionaries that we can use in code\n",
    "ai_ranked_jobs: List[Dict] = ai.convert_relevant_jobs_to_list(ai_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use the `ai_ranked_jobs` to match the Jobs in `scraped_jobs`\n",
    "\n",
    "We can do this by creating a simple \"lookup table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jobs_lookup(all_jobs: List[Job]) -> dict:\n",
    "    \"\"\"This 'lookup table' makes it easier to find relevant jobs within all jobs.\"\"\"\n",
    "    jobs_lookup = {}\n",
    "    for job in all_jobs:\n",
    "        key = f\"{job.company} | {job.title}\"\n",
    "        if key not in jobs_lookup:\n",
    "            jobs_lookup[key] = job\n",
    "    return jobs_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this lookup, we can get back the full `Job` objects that match the AI's results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = create_jobs_lookup(scraped_jobs)\n",
    "jobs = [job for j in ai_ranked_jobs if (job := lookup.get(f\"{j['company']} | {j['title']}\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the jobs found by AI to our `relevant_jobs` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.insert_relevant_jobs(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Send the Top 20 Jobs to the Slack Channel\n",
    "\n",
    "* Slack has a `Block Limit`, so we can only send the top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_jobs = jobs[:20]\n",
    "payload = slack.create_jobs_payload(top_20_jobs)\n",
    "response = slack.post_to_channel(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the next cell runs without error, then the jobs were posted to Slack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert response.ok, f\"Failed to post jobs to Slack: {response.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Do the same for Google Jobs\n",
    "\n",
    "Fortunately, Google Jobs does a much better job of returning relevant jobs, so we don't need to filter with AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jobs import google\n",
    "\n",
    "py = Pylenium(PyleniumConfig())\n",
    "google_jobs = google.scrape(py, google.SOFTWARE_QA_ENGINEER_IN_UTAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results to the `google_jobs` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.insert_google_jobs(google_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the jobs to Slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Jobs shares 20 jobs per page, so we don't need to limit this for Slack\n",
    "google_payload = slack.create_google_jobs_payload(google_jobs)\n",
    "google_response = slack.post_to_channel(google_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the next cell runs without error, then the jobs were posted to Slack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert google_response.ok, f\"Failed to post jobs to Slack: {google_response.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Indeed Jobs Found: 23\n",
      "5 Sample Jobs: \n",
      "\n",
      "Junior QA Engineer Remote Technology, Inc.\n",
      "Jr. QA Engineer Kyla\n",
      "QA Manual Engineer EX2 Outcoding\n",
      "QA Tester Bad Robot Games\n",
      "QA Engineer- Mobile Actabl\n"
     ]
    }
   ],
   "source": [
    "print(\"Relevant Indeed Jobs Found:\", len(jobs))\n",
    "print(\"5 Sample Jobs:\", \"\\n\")\n",
    "for j in jobs[:5]:\n",
    "    print(j.title, j.company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Indeed Jobs Scraped: 75\n",
      "5 Sample Jobs: \n",
      "\n",
      "Angular Software Engineer ES&S Voter Registration LLC\n",
      "Frontend Software Engineer Resourcely\n",
      "Backend Software Engineer, Core and Monetization Pinterest\n",
      "Full Stack Software Engineer, Core and Monetization Pinterest\n",
      "Software Engineer Dow Jones\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Indeed Jobs Scraped:\", len(scraped_jobs))\n",
    "print(\"5 Sample Jobs:\", \"\\n\")\n",
    "for j in scraped_jobs[:5]:\n",
    "    print(j.title, j.company)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
